{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/home/asrulsibaoel/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"data/offroad-dataset-ii-instance\"\n",
    "IMAGE_TEST_PATH = \"data/test_samples/sample1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pretrained YOLOv8-seg Model\n",
    "model = YOLO(\"yolov8-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "epochs = 50\n",
    "image_size = 640\n",
    "batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dataset YAML\n",
    "# Create a dataset YAML file pointing to your drone/satellite images and annotations.\n",
    "\n",
    "# Train the Model\n",
    "model.train(\n",
    "    data=os.path.join(DATASET_PATH, \"data.yaml\"),  # Path to your dataset YAML\n",
    "    epochs=epochs,\n",
    "    imgsz=image_size,\n",
    "    batch=batch,\n",
    "    device=0  # Use GPU if available\n",
    ")\n",
    "\n",
    "# Evaluate the Model\n",
    "results = model.val()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = IMAGE_TEST_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "results = model.predict(source=image, save=True, conf=0.5)\n",
    "\n",
    "# Visualize Results\n",
    "for result in results:\n",
    "    mask = result.masks.data[0].numpy()  # Access first mask\n",
    "    cv2.imshow(\"Segmented Road\", mask)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Size Calculation  \n",
    "\n",
    "Approach:\n",
    "1. Segment the Road  \n",
    "Use the segmentation output to identify the road pixels or regions.\n",
    "\n",
    "2. Calculate Dimensions  \n",
    "Convert pixel dimensions to real-world measurements using the image's spatial resolution or ground sampling distance (GSD).\n",
    "\n",
    "3. Estimate Width and Area  \n",
    "Extract road contours and calculate the width, length, and area.\n",
    "\n",
    "4. Real-World Scaling  \n",
    "Use metadata such as drone altitude, camera resolution, or satellite GSD for accurate scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Road Masks  \n",
    "After running the segmentation model, extract the mask of the road:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = results[0].masks.data.numpy()  # Extract masks\n",
    "\n",
    "# Combine masks into a single binary mask (if necessary)\n",
    "road_mask = np.zeros_like(image[:, :, 0])\n",
    "for mask in masks:\n",
    "    road_mask = np.maximum(road_mask, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Contours and Calculate Size  \n",
    "Using OpenCV, find the road's contours and calculate its dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours\n",
    "contours, _ = cv2.findContours(road_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Analyze contours\n",
    "for contour in contours:\n",
    "    # Approximate the contour to a polygon\n",
    "    epsilon = 0.01 * cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "    \n",
    "    # Get bounding box\n",
    "    x, y, w, h = cv2.boundingRect(approx)\n",
    "    road_width = w  # Width in pixels\n",
    "    road_length = h  # Length in pixels\n",
    "    \n",
    "    # Calculate area\n",
    "    road_area = cv2.contourArea(contour)\n",
    "    \n",
    "    print(f\"Road Width (pixels): {road_width}\")\n",
    "    print(f\"Road Length (pixels): {road_length}\")\n",
    "    print(f\"Road Area (pixels): {road_area}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Pixels to Real-World Units  \n",
    "If using drone or satellite imagery:\n",
    "- **Drone Images**:  \n",
    "$\\ RealWorldWidth(m) = {\\frac{Width(px) \\times SensorWidth(mm)}{ImageWidth(px)}}\\times{\\frac{Altitude(m)}{FocalLength(m)}}$\n",
    "\n",
    "- **Satelite Images**  \n",
    "Use Ground Sampling Distance (GSD) to scale pixel dimensions:  \n",
    "$\\ RealWorldWidth(m) = Width(px) \\times GSD(m/pixel)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for satellite/drone image scaling\n",
    "pixel_width = road_width\n",
    "pixel_length = road_length\n",
    "gsd = 0.1  # Example: 0.1 meters per pixel (adjust based on metadata)\n",
    "\n",
    "real_width = pixel_width * gsd\n",
    "real_length = pixel_length * gsd\n",
    "\n",
    "print(f\"Road Width (meters): {real_width}\")\n",
    "print(f\"Road Length (meters): {real_length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize The Results\n",
    "Overlay measurements on the image for better interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m contour \u001b[38;5;129;01min\u001b[39;00m contours:\n\u001b[1;32m      3\u001b[0m     x, y, w, h \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mboundingRect(contour)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "output_image = image.copy()\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(output_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    cv2.putText(output_image, f\"Width: {real_width:.2f}m\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Road Dimensions\", output_image)\n",
    "cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
