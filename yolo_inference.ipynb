{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asrulsibaoel/miniconda3/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Optional, Union, Any\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('aerial_detection.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AerialModelConfig:\n",
    "    img_size: int = 1024          # Larger size for aerial details\n",
    "    tile_size: int = 1024         # Size for tiling large images\n",
    "    tile_overlap: int = 128       # Overlap between tiles\n",
    "    batch_size: int = 8           # Reduced due to larger images\n",
    "    num_epochs: int = 100\n",
    "    learning_rate: float = 0.01\n",
    "    num_classes: int = 1\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_type: str = \"yolov8l.pt\"  # Larger model for complex features\n",
    "    min_visibility: float = 0.15   # Minimum object visibility threshold\n",
    "    cache_images: bool = True      # Cache images in memory for faster training\n",
    "    save_period: int = 10          # Save checkpoint every N epochs\n",
    "    project_name: str = \"aerial_haul_road_detection\"\n",
    "    experiment_name: str = f\"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    \"\"\"Handle preprocessing of aerial/satellite images\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def enhance_contrast(image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply CLAHE contrast enhancement\"\"\"\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
    "        return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    @staticmethod\n",
    "    def tile_image(\n",
    "        image: np.ndarray,\n",
    "        tile_size: int,\n",
    "        overlap: int\n",
    "    ) -> List[Tuple[np.ndarray, Tuple[int, int]]]:\n",
    "        \"\"\"Split large images into overlapping tiles\"\"\"\n",
    "        tiles = []\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        for y in range(0, h-overlap, tile_size-overlap):\n",
    "            for x in range(0, w-overlap, tile_size-overlap):\n",
    "                end_y = min(y + tile_size, h)\n",
    "                end_x = min(x + tile_size, w)\n",
    "                tile = image[y:end_y, x:end_x]\n",
    "\n",
    "                # Pad if tile is smaller than tile_size\n",
    "                if tile.shape[0] != tile_size or tile.shape[1] != tile_size:\n",
    "                    padded_tile = np.zeros(\n",
    "                        (tile_size, tile_size, 3), dtype=np.uint8)\n",
    "                    padded_tile[:tile.shape[0], :tile.shape[1], :] = tile\n",
    "                    tile = padded_tile\n",
    "\n",
    "                tiles.append((tile, (x, y)))\n",
    "\n",
    "        return tiles\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_predictions(\n",
    "        tiles_predictions: List[Dict[str, Any]],\n",
    "        original_size: Tuple[int, int],\n",
    "        tile_size: int,\n",
    "        overlap: int\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Merge predictions from tiles back to original image size\"\"\"\n",
    "        merged_boxes = []\n",
    "        merged_scores = []\n",
    "        merged_classes = []\n",
    "\n",
    "        for pred, (x_offset, y_offset) in tiles_predictions:\n",
    "            if pred.boxes.xyxy.shape[0] > 0:\n",
    "                # Adjust coordinates based on tile position\n",
    "                boxes = pred.boxes.xyxy.cpu().numpy()\n",
    "                boxes[:, [0, 2]] += x_offset\n",
    "                boxes[:, [1, 3]] += y_offset\n",
    "\n",
    "                # Add predictions\n",
    "                merged_boxes.extend(boxes)\n",
    "                merged_scores.extend(pred.boxes.conf.cpu().numpy())\n",
    "                merged_classes.extend(pred.boxes.cls.cpu().numpy())\n",
    "\n",
    "        # Perform NMS on merged predictions\n",
    "        if merged_boxes:\n",
    "            merged_boxes = np.array(merged_boxes)\n",
    "            merged_scores = np.array(merged_scores)\n",
    "            merged_classes = np.array(merged_classes)\n",
    "\n",
    "            # Convert to YOLO format for NMS\n",
    "            merged_predictions = {\n",
    "                'boxes': torch.from_numpy(merged_boxes),\n",
    "                'scores': torch.from_numpy(merged_scores),\n",
    "                'classes': torch.from_numpy(merged_classes)\n",
    "            }\n",
    "        else:\n",
    "            merged_predictions = {\n",
    "                'boxes': torch.zeros((0, 4)),\n",
    "                'scores': torch.zeros(0),\n",
    "                'classes': torch.zeros(0)\n",
    "            }\n",
    "\n",
    "        return merged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    \"\"\"Prediction class for aerial imagery\"\"\"\n",
    "\n",
    "    def __init__(self, model_path: str, config: AerialModelConfig) -> None:\n",
    "        self.model = YOLO(model_path)\n",
    "        self.config = config\n",
    "\n",
    "    def predict_large_image(\n",
    "        self,\n",
    "        image_path: str,\n",
    "        conf_threshold: float = 0.25,\n",
    "        iou_threshold: float = 0.45\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Handle prediction for large aerial images using tiling\"\"\"\n",
    "        # Load and preprocess image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        original_size = image.shape[:2]\n",
    "\n",
    "        # Enhanced contrast\n",
    "        image = ImageProcessor.enhance_contrast(image)\n",
    "\n",
    "        # Generate tiles\n",
    "        tiles = ImageProcessor.tile_image(\n",
    "            image,\n",
    "            self.config.tile_size,\n",
    "            self.config.tile_overlap\n",
    "        )\n",
    "\n",
    "        # Predict on each tile\n",
    "        tiles_predictions = []\n",
    "        for tile, (x, y) in tiles:\n",
    "            prediction = self.model.predict(\n",
    "                tile,\n",
    "                conf=conf_threshold,\n",
    "                iou=iou_threshold,\n",
    "                verbose=False\n",
    "            )[0]\n",
    "\n",
    "            tiles_predictions.append((prediction, (x, y)))\n",
    "\n",
    "        # Merge predictions\n",
    "        merged_predictions = ImageProcessor.merge_predictions(\n",
    "            tiles_predictions,\n",
    "            original_size,\n",
    "            self.config.tile_size,\n",
    "            self.config.tile_overlap\n",
    "        )\n",
    "\n",
    "        return merged_predictions\n",
    "\n",
    "    def visualize_predictions(\n",
    "        self,\n",
    "        image_path: str,\n",
    "        predictions: Dict[str, torch.Tensor],\n",
    "        output_path: str,\n",
    "        class_names: List[str]\n",
    "    ) -> None:\n",
    "        \"\"\"Visualize predictions on the image\"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Draw boxes\n",
    "        for box, score, class_id in zip(\n",
    "            predictions['boxes'],\n",
    "            predictions['scores'],\n",
    "            predictions['classes']\n",
    "        ):\n",
    "            x1, y1, x2, y2 = box.cpu().numpy().astype(int)\n",
    "            class_id = int(class_id)\n",
    "\n",
    "            # Draw box\n",
    "            cv2.rectangle(\n",
    "                image,\n",
    "                (x1, y1),\n",
    "                (x2, y2),\n",
    "                (0, 255, 0),\n",
    "                2\n",
    "            )\n",
    "\n",
    "            # Add label\n",
    "            label = f\"{class_names[class_id]} {score:.2f}\"\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                label,\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                2\n",
    "            )\n",
    "\n",
    "        # Save result\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AerialModelConfig()\n",
    "\n",
    "    # Setup logging\n",
    "logging.info(\n",
    "    f\"Starting aerial haul road detection pipeline with config: {config}\")\n",
    "\n",
    "class_names = [\"haul_road\"]\n",
    "\n",
    "# Example of prediction on a large image\n",
    "predictor = Predictor(\n",
    "    model_path=f\"{\n",
    "        config.project_name}/{config.experiment_name}/weights/best.pt\",\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Predict on a test image\n",
    "test_image_path = \"path/to/test/image.jpg\"\n",
    "predictions = predictor.predict_large_image(\n",
    "    test_image_path,\n",
    "    conf_threshold=0.25,\n",
    "    iou_threshold=0.45\n",
    ")\n",
    "\n",
    "# Visualize results\n",
    "predictor.visualize_predictions(\n",
    "    test_image_path,\n",
    "    predictions,\n",
    "    output_path=f\"\"\"{\n",
    "        config.project_name}/{config.experiment_name}/predictions/test_prediction.jpg\"\"\",\n",
    "    class_names=class_names\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
